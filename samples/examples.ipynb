{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "678ecbdd",
   "metadata": {},
   "source": [
    "## Context Usability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "283c7163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikildev\\.conda\\envs\\llm_uncertainty_evals\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Simple Question---:\n",
      "Generating RAG output...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at C:\\Users\\nikildev\\AppData\\Local\\NikilP\\CLUE-PYTHON\\Cache\\facebook_bart-large-mnli and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated output: The capital of France is Paris. It's also the most populous city in the country, which is a common trend among capital cities worldwide.\n",
      "Context | Usability Score\n",
      "Paris is the capital and most populous city of France. | 0.337\n",
      "I am huge fan of MacDonalds. | 0.362\n",
      "The capital cities of the world are usually the most populous cities in their respective countries. | 0.336\n",
      "Reddit is a better social media platform than every other out there. | 0.418\n"
     ]
    }
   ],
   "source": [
    "from llm_uncertainty_evals.evaluate import calculate_contexts_usability\n",
    "print(\"----Simple Question---:\")\n",
    "question1 = \"What is the capital of France?\"\n",
    "contexts1 = [\"Paris is the capital and most populous city of France.\",\n",
    "             \"I am huge fan of MacDonalds.\",\n",
    "            \"The capital cities of the world are usually the most populous cities in their respective countries.\",\n",
    "            \"Reddit is a better social media platform than every other out there.\"]\n",
    "scores1 = calculate_contexts_usability(question=question1,retrieved_contexts=contexts1,generated_output=None,max_output_sequences=1)\n",
    "print(f\"Generated output: {scores1.generated_output}\")\n",
    "print(\"Context | Usability Score\")\n",
    "print('\\n'.join(f\"{contexts1[idx]} | {round(scores1.usability_scores[idx],3)}\" for idx in range(len(contexts1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b17ec235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Tricky Question---:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at C:\\Users\\nikildev\\AppData\\Local\\NikilP\\CLUE-PYTHON\\Cache\\facebook_bart-large-mnli and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context | Usability Score\n",
      "The Border–Gavaskar Trophy is one of the premier bilateral trophies in Test cricket. Both teams have a reputation of being difficult to beat at home.  | 0.219\n",
      "This is borne out by India winning 8 out of 9 series held in India, and Australia winning 4 out of 7 series held in Australia, as of the conclusion of the 2022–23 series.  | 0.22\n",
      "The away wins achieved by Australia (2004–05) and India (2018–19 and 2020–21) have earned places in cricket folklore. Both teams have achieved similar number of Test and series wins, and the trophy has changed hands frequently. \n",
      "The competitiveness of the series is also reflected in that in both 2000–01 and 2007–08, it was India who ended Australian streaks of 16 consecutive Test wins.  | 0.233\n",
      "The 2000–01 series was labelled as the \"final frontier\" for Australia by their captain Steve Waugh due to the difficulty of winning in India, and was closely fought on both sides.  | 0.237\n"
     ]
    }
   ],
   "source": [
    "print(\"----Tricky Question---:\")\n",
    "question2 = \"Who won Border-Gavaskar trophy in 2023??\"\n",
    "contexts2 = [\n",
    "\"\"\"The Border–Gavaskar Trophy is one of the premier bilateral trophies in Test cricket. Both teams have a reputation of being difficult to beat at home. \"\"\",\n",
    "\"\"\"This is borne out by India winning 8 out of 9 series held in India, and Australia winning 4 out of 7 series held in Australia, as of the conclusion of the 2022–23 series. \"\"\",\n",
    "\"\"\"The away wins achieved by Australia (2004–05) and India (2018–19 and 2020–21) have earned places in cricket folklore. Both teams have achieved similar number of Test and series wins, and the trophy has changed hands frequently. \n",
    "The competitiveness of the series is also reflected in that in both 2000–01 and 2007–08, it was India who ended Australian streaks of 16 consecutive Test wins. \"\"\",\n",
    "\"\"\"The 2000–01 series was labelled as the \"final frontier\" for Australia by their captain Steve Waugh due to the difficulty of winning in India, and was closely fought on both sides. \"\"\"\n",
    "]\n",
    "outputs2 = [\"I do not know.\"]\n",
    "scores2 = calculate_contexts_usability(question=question2,retrieved_contexts=contexts2,generated_output=outputs2)\n",
    "print(\"Context | Usability Score\")\n",
    "print('\\n'.join(f\"{contexts2[idx]} | {round(scores2.usability_scores[idx],3)}\" for idx in range(len(contexts2))))\n",
    "\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb00d7c8",
   "metadata": {},
   "source": [
    "## Context Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011f15a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Simple Question---:\n",
      "Sentence Transformer model is ready for use.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at C:\\Users\\nikildev\\AppData\\Local\\NikilP\\CLUE-PYTHON\\Cache\\facebook_bart-large-mnli and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Output Sequences: [\"The capital of France is Paris. It's also the most populous city in the country, which is a common trend among capital cities worldwide.\", \"The capital of France is Paris. It's also the most populous city in the country, which is a common trend among capital cities worldwide.\", \"The capital of France is Paris. It's also the most populous city in the country, which is a common trend among capital cities worldwide.\"]\n",
      "Generated Concepts: [['Capital cities', 'Paris as the capital of France', 'Population trends in capital cities'], ['Capital cities', 'Paris as the capital of France', 'Population trends in capital cities'], ['Capital cities', 'Paris as the capital of France', 'Population trends in capital cities']]\n",
      "Pooled Concepts: ['Capital cities', 'Paris as the capital of France', 'Population trends in capital cities']\n",
      "Uncertainty Scores: [0.49793106007008653, 0.5608150667823701, 0.5346121398116763]\n"
     ]
    }
   ],
   "source": [
    "from llm_uncertainty_evals.evaluate import calculate_model_uncertainty\n",
    "from llm_uncertainty_evals.datatypes import ModelUncertainty\n",
    "\n",
    "print(\"----Simple Question---:\")\n",
    "question3 = \"What is the capital of France?\"\n",
    "contexts3 = [\"Paris is the capital and most populous city of France.\",\n",
    "             \"I am huge fan of MacDonalds.\",\n",
    "            \"The capital cities of the world are usually the most populous cities in their respective countries.\",\n",
    "            \"Reddit is a better social media platform than every other out there.\"]\n",
    "scores3:ModelUncertainty = calculate_model_uncertainty(question=question3,retrieved_contexts=contexts3)\n",
    "print(f\"Generated Output Sequences: {scores3.output_sequences}\")\n",
    "print(f\"Generated Concepts: {scores3.extracted_concepts}\")\n",
    "print(f\"Pooled Concepts: {scores3.pooled_concepts}\")\n",
    "print(f\"Uncertainty Scores: {scores3.uncertainty_scores}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_uncertainty_evals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
